version: '3.8'

services:
  mlflow:
    image: python:3.9-slim
    command: mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts --host 0.0.0.0 --port 5000
    ports:
      - "5000:5000"
    volumes:
      - mlflow_data:/mlflow
    networks:
      - recommender_network

  fastapi_recommender:
    build:
      context: ./fastapibaru
      dockerfile: Dockerfile
    ports:
      - "8000:80"
    volumes:
      - ./modelbaru:/app/models
      - ./fastapibaru/app:/app/app
    environment:
      - MODELS_DIR=/app/models
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'
    restart: unless-stopped
    networks:
      - recommender_network

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf  # Perhatikan path!
    depends_on:
      - fastapi_recommender
      - mlflow
    networks:
      - recommender_network

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    command: --config.file=/etc/prometheus/prometheus.yml
    networks:
      - recommender_network

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana2/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana2/datasources:/etc/grafana/provisioning/datasources
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
    networks:
      - recommender_network

volumes:
  prometheus_data: {}
  grafana_data: {}
  mlflow_data: {}

networks:
  recommender_network:
    driver: bridge